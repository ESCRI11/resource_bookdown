# (PART) Developers {-}

# DSLite: DataSHIELD Implementation on Local Datasets

DSLite is a serverless [DataSHIELD Interface (DSI)](https://github.com/datashield/DSI/) implementation whose purpose is to mimic
the behavior of a distant (virtualized or barebone) data repository server (see [DSOpal](https://github.com/datashield/DSOpal) for instance). The datasets that are being analyzed must be fully accessible in the local environment and then the non-disclosive constraint of the analysis is not relevant for DSLite: some DSLite functionalities allow inspection of what is under the hood of the DataSHIELD computation nodes, making it a perfect tool for DataSHIELD analysis package developers.


## Development Environment Setup

### DataSHIELD Packages

Both client and server side packages must be installed in your local R session. The entry point is still the client side package and DSLite will automatically load the corresponding server side package on DataSHIELD aggregate and assignment functions call, based on the DataSHIELD configuration. The minimum required packages are:

```{r install_resourcer, eval=FALSE}
install.packages(c("resourcer", "DSLite"), dependencies = TRUE)
install.packages("dsBase", repos = c("https://cloud.r-project.org", "https://cran.obiba.org"), dependencies = TRUE)
```



### Test Datasets

DSLite comes with a set of datasets that can be easily loaded. You can also provide your own to illustrate a specific data analysis function.

### R Package Development Tools

We recommend using the following tools to facilitate R package development:

* [devtools](https://www.rdocumentation.org/packages/devtools), the collection of package development tools,
* [usethis](https://www.rdocumentation.org/packages/usethis), automate package and project setup tasks that are otherwise performed manually,
* [testthat](https://www.rdocumentation.org/packages/testthat), for unit testing,
* [roxygen2](https://www.rdocumentation.org/packages/roxygen2), for writing documentation in-line with code,
* [Rstudio](https://rstudio.com/), the R editor that integrates the tools mentioned above and more.

## DataSHIELD Development Flow

The typical development flow, using DSLite, is:

1. Build and install your client and/or server side DataSHIELD packages.
2. Create a new DSLiteServer object instance, refering test datasets. Use or alter the default DataSHIELD configuration.
3. Test your DataSHIELD client/server functions.
4. Debug DataSHIELD server nodes using DSLiteServer methods.

### DSLiteServer

After your client and/or server side DataSHIELD packages have been built and installed, a new DSLiteServer object instance must be created. 

Some DSLiteServer methods can be used to verify or modify the DSLiteServer behaviour:

* `DSLiteServer$strict()`
* `DSLiteServer$home()`

See the R documentation of the DSLiteServer class for details.

As an example:

```{r eval=FALSE}
library(DSLite)
# prepare test data in a light DS server
data("CNSIM1")
data("CNSIM2")
data("CNSIM3")
dslite.server <- newDSLiteServer(tables=list(CNSIM1=CNSIM1, CNSIM2=CNSIM2, CNSIM3=CNSIM3))
# load corresponding DataSHIELD login data
data("logindata.dslite.cnsim")
```

The previous example can be simplified using the set-up functions based on the provided test datasets:

```{r eval=FALSE}
library(DSLite)
# load CNSIM test data
logindata.dslite.cnsim <- setupCNSIMTest()
```

### DataSHIELD Configuration

The DataSHIELD configuration (aggregate and assign functions, R options) is automatically discovered by inspecting the R packages installed and having some DataSHIELD settings defined, either in their `DESCRIPTION` file or in a `DATASHIELD` file. 

This default configuration extracting function is:

```{r eval=FALSE}
DSLite::defaultDSConfiguration()
```

The list of the DataSHIELD R packages to be inspected (or excluded) when building the default configuration can be specified as parameters of `defaultDSConfiguration()`.

The DataSHIELD configuration can be specified at DSLiteServer creation time or afterwards with some DSLiteServer methods that can be used to verify or modify the DSLiteServer configuration:

* `DSLiteServer$config()`
* `DSLiteServer$aggregateMethods()`
* `DSLiteServer$aggregateMethod()`
* `DSLiteServer$assignMethods()`
* `DSLiteServer$assignMethod()`
* `DSLiteServer$options()`
* `DSLiteServer$option()`

See the R documentation of the DSLiteServer class for details.

As an example:

```{r eval=FALSE}
# verify configuration
dslite.server$config()
```

## DataSHIELD Sessions

The following figure illustrates a setup where a single DSLiteServer holds several data frames and is used by two different DataSHIELD Connection ([DSConnection](https://github.com/datashield/DSI)) objects. All these objects live in the same R environment (usually the Global Environment). The "server" is responsible for managing DataSHIELD sessions that are implemented as distinct R environments inside of which R symbols are assigned and R functions are evaluated. Using the [R environment](https://adv-r.hadley.nz/environments.html) paradigm ensures that the different DataSHIELD execution context (client and servers) are contained and exclusive from each other.

![DSLite architecture](https://raw.githubusercontent.com/datashield/DSLite/master/inst/images/dslite.png)

After performing the login DataSHIELD phase, the DSLiteServer holds the different DataSHIELD server side sessions, i.e. R environments identified by an ID. These IDs are also stored within the DataSHIELD connection objects that are the result of the `datashield.login()` call. The following example shows how to access these session IDs:

```{r eval=FALSE}
# datashield logins and assignments
conns <- datashield.login(logindata.dslite.cnsim, assign=TRUE)
# get the session ID of "sim1" node connection object
conns$sim1@sid
# the same ID is in the DSLiteServer
dslite.server$hasSession(conns$sim1@sid)
```

## Debugging


Thanks to the DSLiteServer capability of allowing its configuration to be modified at any time, it is possible to add some debugging functions without polluting the DataSHIELD package you are developing.


For instance, this code adds an aggregate function `print()`: 

```{r eval=FALSE}
# add a print method to configuration
dslite.server$aggregateMethod("print", function(x){ print(x) })
# and use it to print the D symbol
datashield.aggregate(conns, quote(print(D)))
```

Another option is to get a symbol value from the server into the client environment. This can be very helpful for complex data structures. The following example illustrates usage of a shortcut function that iterates over all the connection objects and get the corresponding symbol value:

```{r eval=FALSE}
# get data represented by symbol D for each DataSHIELD connection
data <- getDSLiteData(conns, "D")
# get data represented by symbol D from a specific DataSHIELD connection
data1 <- getDSLiteData(conns$sim1, "D")
```

## Limitations

### Function Parameters Parser

The main difference with a regular DSI implementation (such as the one of DSOpal) is that the arguments of the DataSHIELD functional calls are not parsed in DSLite. The only R language element that is inspected and handled is the name of the functions, that are replaced by the ones defined in the DataSHIELD configuration.

For instance the following expression, which includes a function call in the formula, is valid for the DSLiteServer but not for Opal:

```{r eval=FALSE}
someregression(D$height ~ D$diameter + poly(D$length,3,raw=TRUE))
```

As a consequence, DataSHIELD R package development can take advantage of DSLite flexibility for rapid development but will never replace testing on regular DataSHIELD infrastructure using DSOpal.

### Server Side Environments

For each of the DataSHIELD nodes, the server side code is evaluated within an environment that has no parent, i.e. detached from the global environment where the client code is executed. Some R functions have a parameter that allows to specify to which environment they apply, for instance `assign()`, `get()`, `eval()`, `as.formula()`, etc. Their `env` (or `envir`) parameter default value is `parent.frame()` which is the global environment when executed in Opal's R server, because it is the parent frame of the package's namespace where the function is defined. In DSLiteServer, the parent frame must be the environment where the server code is evaluated. In order to be consistent between these two execution contexts (Opal R server and DSLiteServer), you must specify the `env` (or `envir`) value explicitly to be `parent.frame()`, which is the parent frame of the block being executed (either the global environment in Opal context, or the environment defined in DSLiteServer).

Example of a valid server side piece of code that assigns a value to a symbol in the DataSHIELD server's environment (being the Opal R server's global environment or a DSLiteServer's environment):

```{r eval=FALSE}
base::assign(x = "D", value = someValue, envir = parent.frame())
```

See also the [Advanced R - Environments](http://adv-r.had.co.nz/Environments.html) documentation to learn more about environments.

## Environment setup for DataSHIELD package development. A proposition

The following section contains a proposition on how to setup a whole environment to develop DataSHIELD packages using DSLite and RStudio, as well as a complete example. It is targeted at new developers of DataSHIELD packages that need some guidance on the first steps. Please note that anything described on this section is just a proposition and it can be modified and adapted to anyones liking, take it as a starting point.

### Folders and files {#fandfiles}

To speed up the development process, the most practical approach to setting up the folders and files is illustrated on the Figure \@ref(fig:development_proposition1). The idea is to have two folders that contain each one a package, that means one to be used in the client and one on the server (virtualized server on this development approach); outside those two folders there is the testing script that will be used to call the new functions.

```{r development_proposition1, echo=FALSE, fig.cap="Folders and files proposal", out.height= '25%', fig.align='center'}
knitr::include_graphics("fig/dsliteexample.png")
```

Inside each folder, a typical R package structure is to be found. This is further detailed [here](#package_info) and [here](https://r-pkgs.org/). If the reader does not have prior experience on R package development, there is the option of setting up a package folder through:

```
RStudio -> File -> New Project... -> New Directory -> R Package 
```

The typical style convention for DataSHIELD is to name the client package as *dsXClient* and the associated server package as *dsX*. The client package will contain the functions that the user will use, those functions will be basically triggers to the server functions, more information about that on the following lines.

### Development of a function

There is many information about [DataSHIELD](https://data2knowledge.atlassian.net/wiki/spaces/DSDEV/overview) and how it works. A very brief introduction will be provided on this section to help.

When developing a function, we have to develop both the server function and the client function. The aim of the client function (your RStudio instance) is to send an instruction to the server that will or will not have a return to you; and the aim of the server function is to perform an action(s) on an object that it contains, and make sure that if there is an output to the client, it is non disclosive.

We have already described a classification between functions that do and do not have outputs to the client, in DataSHIELD they are called `AGGREGATE` functions (output to the client) and `ASSIGN` functions (NO output to the client).

It is important to always have in mind that the objects that are being manipulated only exist on the servers, and not on the client, with that in mind let's take a look at a basic client function.

```{r exampleClient1, eval = FALSE}
ds.basicFunction <- function(object, option) {
  
}
```

This is a basic function that will modify an object on the server that has one option parameter. Before writing any more code, let's take a minute to understand that the `object` variable and `option` variable will be strings, since they do not exist on the client side. The `object` variable is the name of the object that we want to modify on the server, and the `option` variable is a string that in this example will refer to a bool (TRUE/FALSE).

Let's now build the function call that will be done on the client.

```{r exampleClient2}
ds.basicFunction <- function(object, option) {
 
  cally <- paste0("basicFunctionDS(", object, ", ", option, ")")
  return(cally)
   
}

ds.basicFunction("dataset1", "FALSE")
```

As it can be seen, we have now created a string that contains a function call that we want to execute on the server, the only thing left to do is to send this instruction to the server. Before doing that let's make clear the style used here. For the client functions we use ds.X and the associated server function is named XDS. Now we can use as example the following function that we have created on our server package.

```{r exampleServer1, eval = FALSE}
basicFunctionDS <- function(object, option){
  if(option){
    object <- sum(object)
  }
  else{
    object <- mean(object)
  }
  return(object)
}
```

What needs to be noted about the example server function is 1) Here we are using the input arguments of the functions as R objects, since this will be executed on a server that is expected to have them. On this particular example `object` must be a numerical vector and `option` a bool (this is a very simple example with no class checking of the arguments); 2) We have a return, so this can be an `AGGREGATE` or `ASSIGN` function, more information on that in the following lines, no need to worry at this stage.

Having explained the server function, let's now retake the client function. We now have our server function defined and what is left to be done is to actually call it. To do so we make use of the DSI package, at this point is when we have to decide if the function call will be `AGGREGATE` or `ASSIGN`.

```{r exampleClient3,eval = FALSE}
# AGGREGATE
DSI::datashield.aggregate(conns, as.symbol(cally))

# ASSIGN
DSI::datashield.assign.expr(conns, name, as.symbol(cally))
```

The return of the server function will be passed to the client on a `AGGREGATE` function and it will be assigned to a new object (on the server) on a `ASSIGN` function.

If we want to create a function that will have an output to the client, we use `DSI::datashield.aggregate`, this function needs a connection object and the previously formatted string; while if we just want to create a new object on the server we use `DSI::datashield.assign.expr`, this function also needs the connection object as well as a string (`name` on the example) that indicates the name the new object will have on the server. Let's say for this example we are creating a `AGGREGATE` function, our final function will look like this:

```{r exampleClient4, eval = FALSE}
ds.basicFunction <- function(object, option, datasources = NULL) {
 
  if (is.null(datasources)) {
    datasources <- DSI::datashield.connections_find()
  }
  
  cally <- paste0("basicFunctionDS(", object, ", ", option, ")")
  result <- DSI::datashield.aggregate(datasources, as.symbol(cally))
  
  return(result)
  
}
```

On this final example, there is already the handling of the connection object, which is done using the DSI package as well.

Now that we have both our client and server functions ready, we are almost ready to test them using DSLite, before doing that there are still a couple of steps to be done.

Document using roxygen both functions, to do so go to:

```{}
Code -> Insert Roxygen Skeleton
```

And complete the header that has been added to the funcion (this step has to be done for both client and server functions).

For both the client and server packages, the NAMESPACE has to be updated to declare this new functions, to do so, find both folders on the RStudio Files panel and do the following:

1. Go inside dsX folder on the files panel in RStudio.
2. `More -> Set As Working Directory`
3. On the RStudio Console run the following command: `devtools::document()`
4. Repeat 1, 2 and 3 on the dsXClient folder

There is just one step left to be done, on DataSHIELD server packages there has to be a file that states all the funcions of the package and whether they are `AGGREGATE` or `ASSIGN` functions. This file has to be named `DATASHIELD` (no extension) and has to be placed on `dsX/inst/`. The structure of this file is the following:

```{}
AggregateMethods:
   basicFunctionDS,
   basicFunction2DS
AssignMethods:
   assignFunctionDS,
   assignFunction2DS
```

On our example it would just be:

```{}
AggregateMethods:
   basicFunctionDS
AssignMethods:
```

### Testing of the function

We are now ready to test our new function using DSLite. This will be done from the testing script that we described when talking about the [folders and files](#fandfiles).

On this script, we have to achieve the following:

1. Install the packages we are developing
2. Create (or load) test data
3. Create a virtualized server using DSLite
4. Put the base DataSHIELD package and our new package inside the server
5. Put the test data inside the server
6. Login into the virtualized server
7. Execute the new function and see how it behaves

To simplify the explanation, an example script will now be shown with some comments on it to guide the reader.

```{r exampleTestDSLite, eval = FALSE}
# Make sure the working directory is the test script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Install the current version of both the client and server packages found locally
devtools::install("./dsX")
devtools::install("./dsXClient")

# Load all the required packages
library(dsBase)
library(dsBaseClient)
library(resourcer)
library(DSLite)
library(dsX)
library(dsXClient)

# Create test numerical vector
test_data <- rpois(n = 50, lambda = 10)

# Create virtualized server with DSLite, assign everything needed on it
dslite.server <- newDSLiteServer(tables=list(exposures = test_data),
                                 config = DSLite::defaultDSConfiguration(include=c("dsBase", "dsX")))

builder <- DSI::newDSLoginBuilder()
builder$append(server = "server1", url = "dslite.server", table = "exposures", driver = "DSLiteDriver")
logindata.dslite <- builder$build()
# Login to the virtualized server
conns <- datashield.login(logindata.dslite, assign=T, symbol = "exposures")

# Test the function
ds.basicFunction("exposures", FALSE)

```

With this complete example understood, one must feel now ready to start developing new features for DataSHIELD.